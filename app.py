import streamlit as st
import pandas as pd
import numpy as np
import io
from datetime import datetime

st.set_page_config(page_title="Excelè¡¨æ ¼åˆ†æ / æ ¹å› åˆ†æ", layout="wide")

########################################################
# 0. è³‡æ–™æ¸…æ´— / æ•¸å­—æ¬„åˆ¤æ–· / ç¾¤çµ„è¨ˆç®—
########################################################

ERROR_TOKENS = [
    "", " ", "  ", "\t",
    "#DIV/0!", "#DIV/0", "#VALUE!", "#REF!", "#NAME?", "#N/A",
    "#NUM!", "#NULL!", "ERROR", "Error", "error"
]

def normalize_cell_value(v):
    """ç©ºç™½ / Error / #DIV/0! ç­‰ â†’ 0ï¼Œå…¶å®ƒä¿ç•™åŸå€¼"""
    if pd.isna(v):
        return 0
    if isinstance(v, str):
        vs = v.strip()
        for bad in ERROR_TOKENS:
            if vs == bad or vs.upper() == bad.upper():
                return 0
        return v
    return v

def clean_dataframe(df: pd.DataFrame):
    df_clean = df.copy()
    for col in df_clean.columns:
        df_clean[col] = df_clean[col].apply(normalize_cell_value)
    return df_clean

def can_be_all_numeric_after_clean(series: pd.Series):
    """åˆ¤æ–·æ•´æ¬„(è£œ0å¾Œ)æ˜¯å¦éƒ½èƒ½è½‰æ•¸å­—"""
    def normalize_numeric_like(x):
        if isinstance(x, str):
            return x.replace(",", "").strip()
        return x
    normalized = series.apply(normalize_numeric_like)
    numeric_series = pd.to_numeric(normalized, errors="coerce")
    all_numeric = not numeric_series.isna().any()
    return all_numeric, numeric_series.astype(float)

def get_pure_numeric_cols(df_clean: pd.DataFrame):
    """æ‰¾å¯å®Œå…¨è½‰æˆæ•¸å­—çš„æ¬„ä½"""
    numeric_cols = []
    for col in df_clean.columns:
        all_num, _ = can_be_all_numeric_after_clean(df_clean[col])
        if all_num:
            numeric_cols.append(col)
    return numeric_cols

def summarize_by_dimension(df_clean, target_col, dim_col, mode, top_n=5):
    """
    ç”¨åœ¨ç¬¬ä¸€é (è¡¨æ ¼åˆ†æ)
    mode:
      - contribution: æœ€é«˜è²¢ç»
      - loss: æœ€å¤§è™§æ(è² å€¼)
    """
    total_value = df_clean[target_col].astype(float).sum()
    group_sum = (
        df_clean.groupby(dim_col)[target_col]
        .apply(lambda s: pd.to_numeric(s, errors="coerce").fillna(0).sum())
    )

    # æ’åºä¾ç…§ KPI çš„å½±éŸ¿åŠ›ï¼Œè€Œä¸æ˜¯ç¾¤çµ„åå­—
    # contribution: ç”±å¤§åˆ°å°
    # loss: ç”±è™§æœ€å¤š(è¶Šè² è¶Šå¤§abs)åˆ°è¼ƒå°‘
    if mode == "contribution":
        ordered = group_sum.sort_values(ascending=False)
    elif mode == "loss":
        ordered = group_sum.reindex(group_sum.sort_values(key=lambda x: x.abs(), ascending=False).index)
    else:
        ordered = group_sum

    top_only = ordered.head(top_n)
    other_only = ordered.iloc[top_n:]

    # çµ„ Top5 + å…¶ä»–
    main_rows = top_only.reset_index()
    main_rows.columns = [dim_col, target_col]

    # calc %
    main_rows["pct_of_total_%"] = (
        main_rows[target_col] / total_value * 100
    ).round(2) if total_value != 0 else 0.0

    if len(other_only) > 0:
        other_sum = other_only.sum()
        other_pct = (other_sum / total_value * 100).round(2) if total_value != 0 else 0.0
        other_row = pd.DataFrame([{
            dim_col: "å…¶ä»–",
            target_col: other_sum,
            "pct_of_total_%": other_pct
        }])
        main_rows = pd.concat([main_rows, other_row], ignore_index=True)

    return main_rows, total_value


def filter_df_by_dim_value(df_clean: pd.DataFrame,
                           dim_col: str,
                           dim_value,
                           cols_show=None):
    """
    å›å‚³è©²ç¾¤çµ„çš„åŸå§‹åˆ—æ˜ç´°ï¼Œå­—ä¸²æ¯”å°é¿å…å‹åˆ¥ä¸ä¸€ã€‚
    """
    mask = df_clean[dim_col].astype(str) == str(dim_value)
    sub = df_clean[mask].copy()
    if cols_show is not None:
        sub = sub[cols_show]
    return sub


########################################################
# 1. æ ¹å› åˆ†ææ¨¹ è¨ˆç®—é‚è¼¯
########################################################

def apply_filters_to_df(df, filters: dict):
    """
    filters = {"åœ°å€": "åŒ—å€", "ç”¢å“": "Aç³»åˆ—", ...}
    å›å‚³ç¬¦åˆæ‰€æœ‰æ¢ä»¶çš„subset
    """
    sub = df.copy()
    for col_name, col_val in filters.items():
        if col_val == "__ALL__":
            continue
        sub = sub[sub[col_name].astype(str) == str(col_val)]
    return sub

def compute_top_groups_with_other(df_sub, target_col, split_dim, top_n=5):
    """
    åœ¨ df_sub ä¸­ä½¿ç”¨ split_dim åˆ†ç¾¤ï¼Œè¨ˆç®— target_col åˆè¨ˆ
    1. ä¾çµ•å°å€¼(|kpi_sum|)æ’åº
    2. Top N
    3. å…¶é¤˜åˆä½µæˆ "å…¶ä»–"
    å›å‚³ list[ dict ]:
      {
        "label": ç¾¤çµ„åç¨±,
        "kpi_sum": float,
        "pct": groupå°parentçš„å æ¯”(%),
        "filters": { split_dim: value or "(å…¶ä»–)" },
        "is_other": bool
      }
    """
    total_here = pd.to_numeric(df_sub[target_col], errors="coerce").fillna(0).sum()

    grp = (
        df_sub.groupby(split_dim)[target_col]
        .apply(lambda s: pd.to_numeric(s, errors="coerce").fillna(0).sum())
    )

    if grp.empty:
        return []

    grp_sorted = grp.reindex(grp.abs().sort_values(ascending=False).index)

    top_grp = grp_sorted.head(top_n)
    other_grp = grp_sorted.iloc[top_n:]

    rows = []
    for gval, ksum in top_grp.items():
        pct = 0.0 if total_here == 0 else (ksum / total_here * 100.0)
        rows.append({
            "label": str(gval),
            "kpi_sum": float(ksum),
            "pct": float(pct),
            "filters": {split_dim: str(gval)},
            "is_other": False
        })

    if len(other_grp) > 0:
        other_sum = other_grp.sum()
        other_pct = 0.0 if total_here == 0 else (other_sum / total_here * 100.0)
        rows.append({
            "label": "å…¶ä»–",
            "kpi_sum": float(other_sum),
            "pct": float(other_pct),
            "filters": {split_dim: "(å…¶ä»–)"},
            "is_other": True
        })

    return rows

def compute_dimension_spread(df_sub, target_col, dim_col):
    """
    è©²æ¬„ä½èƒ½è§£é‡‹KPIçš„ç¨‹åº¦(å·®ç•°åº¦): max(group_sum)-min(group_sum)
    """
    grp_series = (
        df_sub.groupby(dim_col)[target_col]
        .apply(lambda s: pd.to_numeric(s, errors="coerce").fillna(0).sum())
    )
    if grp_series.empty:
        return 0.0
    return float(abs(grp_series.max() - grp_series.min()))

def rank_candidate_dims(df_sub, target_col, all_dims, used_dims):
    """
    é‡å°ç›®å‰é€™å€‹ parent subsetï¼Œå“ªäº›æ¬„ä½æœ€å€¼å¾—æ‹†ï¼Ÿ
    å›å‚³ spread å¤§åˆ°å°çš„æ¬„ä½æ¸…å–®ï¼ˆæ’æ‰å·²ç¶“æ‹†éçš„ï¼‰
    """
    scored = []
    for dim in all_dims:
        if dim == target_col:
            continue
        if dim in used_dims:
            continue
        spread = compute_dimension_spread(df_sub, target_col, dim)
        scored.append((dim, spread))

    scored.sort(key=lambda x: x[1], reverse=True)
    return [d for d, _ in scored]


########################################################
# 2. æ¨¹çš„ state (rca_layers) + æˆ‘å€‘çš„æ–°é‚è¼¯ï¼šå–®ä¸€è·¯å¾‘ä¸‹é‘½
########################################################

def init_rca_layers():
    if "rca_layers" not in st.session_state:
        st.session_state["rca_layers"] = []


def get_current_tail_layer():
    """
    å–å¾—ç›®å‰ã€Œæœ€å¾Œä¸€å±¤ã€layerã€‚
    å¦‚æœç›®å‰æ²’æœ‰ä»»ä½•å±¤(åªæœ‰ root KPI)ï¼Œå›å‚³ Noneã€‚
    """
    if "rca_layers" not in st.session_state or len(st.session_state["rca_layers"]) == 0:
        return None
    return st.session_state["rca_layers"][-1]


def build_parent_candidates_from_tail():
    """
    æˆ‘å€‘åªå…è¨±ä½¿ç”¨è€…å¾€"è·¯å¾‘æœ«ç«¯"ç¹¼çºŒé‘½ã€‚
    è¦å‰‡ï¼š
    - å¦‚æœæ•´æ£µæ¨¹é‚„æ²’å±•é–‹ä»»ä½•å±¤ (rca_layers ç©º)ï¼Œ
      åªæœ‰ä¸€å€‹å€™é¸ parent: {}  (å…¨é«”)
    - å¦å‰‡ï¼Œç”¨æœ€å¾Œä¸€å±¤ layer çš„ groups
      ä¹Ÿå°±æ˜¯ä½¿ç”¨è€…å¿…é ˆæŒ‘æœ€å¾Œä¸€å±¤çš„å…¶ä¸­ä¸€å€‹ç¾¤çµ„ç¯€é»ï¼Œå¾€ä¸‹é‘½
    å›å‚³ [(label, filters_dict), ...]
    """
    if len(st.session_state["rca_layers"]) == 0:
        return [("å…¨é«” (ç„¡æ¢ä»¶)", {})]

    tail = st.session_state["rca_layers"][-1]
    tail_parent_filters = tail["parent_filters"]
    split_dim = tail["split_dim"]

    out = []
    for g in tail["groups"]:
        # é€™å€‹ç¾¤çµ„ç¯€é»çš„ filter = tail_parent_filters + { split_dim: è©²ç¾¤çµ„label }
        fdict = {}
        fdict.update(tail_parent_filters)
        fdict[split_dim] = g["label"]
        label_txt = ", ".join([f"{k}={v}" for k,v in fdict.items()])
        if not label_txt:
            label_txt = "(å…¨é«”)"
        out.append((label_txt, fdict))

    # å»é‡
    unique_map = {}
    for lab, fdict in out:
        key = tuple(sorted(fdict.items()))
        unique_map[key] = (lab, fdict)
    final_list = list(unique_map.values())
    return final_list


def add_new_layer(df_clean, target_col, parent_filters, split_dim, top_n=5):
    """
    å° parent_filters subsetï¼Œç”¨ split_dim åˆ†è§£ target_col â†’ Top5+å…¶ä»–
    ç”¢ç”Ÿæˆ–æ›´æ–°ä¸€å€‹ layerã€‚
    è¦å‰‡èª¿æ•´ï¼šé€™å€‹æ–°çš„ layer æ‡‰è©²æˆç‚º"è·¯å¾‘æœ«ç«¯"ã€‚
    å¦‚æœ parent_filters å°ä¸ä¸Šç›®å‰æœ€å¾Œä¸€å±¤å…è¨±çš„çˆ¶ç¯€é»ï¼Œæˆ‘å€‘å°±ä¸åŠ å…¥(ä¿è­·é‚è¼¯)ã€‚
    """
    # å®‰å…¨æª¢æŸ¥ï¼šparent_filters å¿…é ˆæ˜¯å…è¨±çš„ä¸‹é‘½é»ä¹‹ä¸€
    valid_candidates = build_parent_candidates_from_tail()
    valid_filter_sets = [tuple(sorted(f.items())) for (_lab, f) in valid_candidates]
    if tuple(sorted(parent_filters.items())) not in valid_filter_sets:
        # å¦‚æœä¸åœ¨æœ€å¾Œä¸€å±¤çš„å€™é¸æ¸…å–®ï¼Œä»£è¡¨ä½¿ç”¨è€…æƒ³åœ¨ä¸­é–“å±¤é–‹æ–°åˆ†æ”¯ -> ä¸å…è¨±
        return

    df_sub = apply_filters_to_df(df_clean, parent_filters)
    groups = compute_top_groups_with_other(df_sub, target_col, split_dim, top_n=top_n)
    if len(groups) == 0:
        return

    # å¦‚æœå·²ç¶“æœ‰å®Œå…¨ä¸€æ¨£ parent_filters+split_dim çš„å±¤ï¼Œå°±æ›´æ–°å®ƒ
    replaced = False
    for lyr in st.session_state["rca_layers"]:
        if lyr["parent_filters"] == parent_filters and lyr["split_dim"] == split_dim:
            lyr["groups"] = groups
            replaced = True
            break

    if not replaced:
        st.session_state["rca_layers"].append({
            "parent_filters": parent_filters.copy(),
            "split_dim": split_dim,
            "groups": groups,
        })

def remove_layer_by_index(idx_to_remove: int):
    """
    ä¾ index åˆªé™¤æŸå±¤ã€‚
    é€™å¯ä»¥æ˜¯ä¸­é–“å±¤æˆ–æœ€å¾Œä¸€å±¤ã€‚
    ä½†åˆªæ‰ä¹‹å¾Œï¼Œrca_layerså°±æœƒç¸®çŸ­/æ–·è£‚ï¼Œæ–°çš„ "æœ€å¾Œä¸€å±¤" å°±æ˜¯æ–°çš„ä¸‹é‘½é»ã€‚
    """
    if "rca_layers" not in st.session_state:
        return
    if idx_to_remove < 0 or idx_to_remove >= len(st.session_state["rca_layers"]):
        return
    new_layers = []
    for i, lyr in enumerate(st.session_state["rca_layers"]):
        if i != idx_to_remove:
            new_layers.append(lyr)
    st.session_state["rca_layers"] = new_layers


########################################################
# 2A. æŠŠ rca_layers è½‰æˆä¸€æ¢éšå±¤è·¯å¾‘ (levels) çµ¦ SmartArt
########################################################

def value_color_class(val):
    """
    çµ¦æ•¸å€¼ä¸€å€‹ CSS class æ–¹ä¾¿ä¸Šè‰²
    """
    try:
        v = float(val)
    except:
        return "neutral"
    if v < 0:
        return "bad"
    elif v > 0:
        return "good"
    else:
        return "neutral"

def build_tree_path(df_clean, target_col):
    """
    ä¾ç…§ä½¿ç”¨è€…å±•é–‹é †åº (rca_layers append é †åº)ï¼Œ
    ç”¢å‡ºå±¤ç´šæè¿°ï¼Œçµ¦å‰ç«¯ SmartArt é¢¨æ ¼è¦–è¦ºåŒ–ã€‚
    """
    levels = []

    # Root level
    full_total = pd.to_numeric(df_clean[target_col], errors="coerce").fillna(0).sum()
    root_node = {
        "name": target_col,
        "value": full_total,
        "pct": "100.00%",
        "color_class": value_color_class(full_total)
    }
    levels.append({
        "title": "ROOT KPI",
        "subtitle": "å…¨é«”è³‡æ–™",
        "nodes": [root_node]
    })

    # ä¾åºç•«å‡ºæ¯ä¸€å±¤
    for layer in st.session_state["rca_layers"]:
        p_filters = layer["parent_filters"]
        split_dim = layer["split_dim"]
        groups   = layer["groups"]

        df_parent = apply_filters_to_df(df_clean, p_filters)
        parent_total = pd.to_numeric(df_parent[target_col], errors="coerce").fillna(0).sum()

        if len(p_filters)==0:
            pf_str = "å…¨é«”"
        else:
            pf_str = ", ".join([f"{k}={v}" for k,v in p_filters.items()])

        node_list = []
        for g in groups:
            pct_parent = 0.0
            if parent_total != 0:
                pct_parent = g["kpi_sum"]/parent_total*100.0
            node_list.append({
                "name": g["label"],
                "value": g["kpi_sum"],
                "pct": f"{pct_parent:.2f}%",
                "color_class": value_color_class(g["kpi_sum"])
            })

        levels.append({
            "title": f"æ‹†åˆ†æ¬„ä½ï¼š{split_dim}",
            "subtitle": f"çˆ¶æ¢ä»¶: {pf_str}",
            "nodes": node_list
        })

    return levels


########################################################
# 2B. æŠŠ levels ç•«æˆ SmartArt é¢¨æ ¼çš„ HTML/CSS
########################################################

def render_tree_html(levels):
    css = """
    <style>
    .rca-wrapper{
        font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial;
        font-size:13px;
        color:#222;
    }
    .rca-level{
        display:flex;
        flex-direction:column;
        align-items:center;
        margin-bottom:32px;
        position:relative;
    }
    .rca-titlebox{
        text-align:center;
        margin-bottom:12px;
    }
    .rca-title{
        font-size:0.8rem;
        font-weight:600;
        color:#111;
        line-height:1.2;
    }
    .rca-sub{
        font-size:0.7rem;
        color:#666;
        line-height:1.2;
    }
    .rca-branch-row{
        display:flex;
        flex-wrap:wrap;
        justify-content:center;
        gap:16px;
        position:relative;
        padding:8px 0;
        min-height:80px;
    }
    .rca-branch-row-line{
        position:absolute;
        top:-16px;
        left:0;
        right:0;
        height:0;
        border-top:1px solid #999;
        z-index:-1;
    }
    .rca-connector-vertical{
        position:absolute;
        top:-16px;
        left:50%;
        width:0;
        height:16px;
        border-left:1px solid #999;
    }
    .rca-branch{
        position:relative;
        display:flex;
        flex-direction:column;
        align-items:center;
    }
    .rca-branch-connector{
        position:absolute;
        top:-16px;
        left:50%;
        width:1px;
        height:16px;
        border-left:1px solid #999;
    }
    .rca-node-card{
        min-width:120px;
        max-width:160px;
        background:#fff;
        border-radius:8px;
        box-shadow:0 2px 6px rgba(0,0,0,0.08);
        border:1px solid #ddd;
        padding:8px 10px;
        text-align:center;
        line-height:1.3;
        font-size:0.7rem;
    }
    .rca-node-name{
        font-weight:600;
        font-size:0.75rem;
        color:#222;
        margin-bottom:4px;
        word-wrap:break-word;
        word-break:break-all;
    }
    .rca-node-value{
        font-size:0.75rem;
        margin-bottom:2px;
        font-family:Consolas,Menlo,monospace;
        font-weight:600;
        color:#444;
    }
    .rca-node-value.bad{ color:#c62828; }
    .rca-node-value.good{ color:#2e7d32; }
    .rca-node-value.neutral{ color:#444; }
    .rca-node-pct{
        font-size:0.65rem;
        color:#666;
    }
    </style>
    """

    body = ['<div class="rca-wrapper">']

    for idx, level in enumerate(levels):
        title = level["title"]
        subtitle = level["subtitle"]
        nodes = level["nodes"]

        body.append('<div class="rca-level">')

        body.append('<div class="rca-titlebox">')
        body.append(f'<div class="rca-title">{title}</div>')
        body.append(f'<div class="rca-sub">{subtitle}</div>')
        body.append('</div>')

        body.append('<div class="rca-branch-row">')
        if idx > 0:
            body.append('<div class="rca-branch-row-line"></div>')
            body.append('<div class="rca-connector-vertical"></div>')

        for n in nodes:
            body.append('<div class="rca-branch">')
            if idx > 0:
                body.append('<div class="rca-branch-connector"></div>')
            body.append('<div class="rca-node-card">')
            body.append(f'<div class="rca-node-name">{n["name"]}</div>')
            body.append(
                f'<div class="rca-node-value {n["color_class"]}">{n["value"]:,.2f}</div>'
            )
            body.append(f'<div class="rca-node-pct">{n["pct"]}</div>')
            body.append('</div>')  # card
            body.append('</div>')  # branch

        body.append('</div>')  # branch-row
        body.append('</div>')  # level

    body.append('</div>')  # wrapper

    return css + "\n".join(body)


########################################################
# 3. å…±ç”¨å°UIå…ƒä»¶
########################################################

def step_header_small(text):
    st.markdown(
        f"<div style='color:#666;font-size:0.9rem;font-weight:500;margin-top:1rem;'>{text}</div>",
        unsafe_allow_html=True
    )

def big_bold_label(text):
    st.markdown(
        f"<div style='font-size:1.1rem;font-weight:700;margin-bottom:0.4rem;'>{text}</div>",
        unsafe_allow_html=True
    )

def pick_one_from_grid_scrollable(
    options,
    current_value,
    key_prefix,
    columns_per_row=4,
    box_height_px=300
):
    chosen = current_value

    st.markdown(
        f"""
        <div style="
            max-height:{box_height_px}px;
            overflow-y:auto;
            border:1px solid #CCC;
            border-radius:8px;
            padding:8px;
            background-color:#fafafa;
        ">
        """,
        unsafe_allow_html=True
    )

    rows = [options[i:i+columns_per_row] for i in range(0, len(options), columns_per_row)]

    global_idx = 0
    for r_i, row_options in enumerate(rows):
        cols = st.columns(len(row_options))
        for c_i, opt in enumerate(row_options):
            btn_key = f"{key_prefix}_{global_idx}"
            if cols[c_i].button(
                opt,
                key=btn_key,
                use_container_width=True
            ):
                chosen = opt
            global_idx += 1

    st.markdown("</div>", unsafe_allow_html=True)

    return chosen


########################################################
# 4. ç¬¬ä¸€é ï¼šExcelè¡¨æ ¼åˆ†æ (ä¿æŒåŸæœ¬åŠŸèƒ½)
########################################################

def page_table_analysis():
    st.title("ğŸ“Š Excelè¡¨æ ¼åˆ†æå°å·¥å…·")

    st.markdown("""
    ### ğŸ“˜ ä½¿ç”¨èªªæ˜
    æµç¨‹ï¼š  
    Step 1. ä¸Šå‚³ Excelã€é¸æ“‡æ¬²åˆ†æçš„å·¥ä½œè¡¨  
    âš  æ³¨æ„ï¼šå·¥ä½œè¡¨ç¬¬ä¸€åˆ—éœ€ç‚ºæ¬„ä½åç¨±ï¼Œä¸”è¡¨æ ¼å¤–è«‹å‹¿ç•™é›œè³‡æ–™ï¼Œä»¥å…åˆ†æéŒ¯èª¤  
    ç³»çµ±æœƒè‡ªå‹•å°‡ç©ºç™½ / Error / #DIV/0! ç­‰ç•°å¸¸å€¼è£œæˆ 0ã€‚  
    Step 2. é¸åˆ†ææŒ‡æ¨™ (åªèƒ½æ•¸å­—æ¬„)  
    Step 3. é¸æ¨¡å¼ï¼ˆæœ€é«˜è²¢ç» / æœ€å¤§è™§æï¼‰  
    Step 4. é¸åˆ†ç¾¤æ¬„ä½  
    Step 5. å±•é–‹æ˜ç´°  
    Step 6. ä¸‹è¼‰æ˜ç´°  
    <br>
    <span style='color:red; font-weight:bold;'>
    è³‡å®‰è²æ˜ï¼šæ­¤ç¶²ç«™ä¸æœƒè¨˜éŒ„ä½¿ç”¨è€…ä¸Šå‚³çš„æª”æ¡ˆï¼Œä¹Ÿä¸æœƒè¨˜æ†¶ä»»ä½•è³‡è¨Š
    </span>
    """, unsafe_allow_html=True)

    step_header_small("Step 1. ä¸Šå‚³ Excelã€é¸æ“‡æ¬²åˆ†æçš„å·¥ä½œè¡¨")
    big_bold_label("ä¸Šå‚³ Excel (.xls / .xlsx / .xlsm)")

    uploaded_file = st.file_uploader("", type=["xls","xlsx","xlsm"], key="page1_uploader")
    if uploaded_file is None:
        st.stop()

    try:
        xls = pd.ExcelFile(uploaded_file)
        sheet_names = xls.sheet_names
    except Exception as e:
        st.error(f"è®€æª”å¤±æ•—ï¼š{e}")
        st.stop()

    big_bold_label("è«‹é¸æ“‡è¦åˆ†æçš„å·¥ä½œè¡¨")
    chosen_sheet = st.selectbox(
        "é¸æ“‡å·¥ä½œè¡¨(ä¸‹æ‹‰å¼é¸å–®)",
        sheet_names,
        index=0,
        key="page1_sheet"
    )

    if "page1_last_sheet" not in st.session_state:
        st.session_state["page1_last_sheet"] = chosen_sheet
    if chosen_sheet != st.session_state["page1_last_sheet"]:
        for k in ["target_col", "dim_col", "selected_val"]:
            if k in st.session_state:
                del st.session_state[k]
        st.session_state["page1_last_sheet"] = chosen_sheet

    try:
        raw_df = pd.read_excel(uploaded_file, sheet_name=chosen_sheet, header=0)
    except Exception as e:
        st.error(f"è®€å–å·¥ä½œè¡¨å¤±æ•—ï¼š{e}")
        st.stop()

    if raw_df.columns.duplicated().any():
        st.error("è¡¨é ­æœ‰é‡è¤‡æ¬„ä½åç¨±ï¼Œè«‹ä¿®æ­£å¾Œå†ä¸Šå‚³ã€‚")
        st.stop()
    if any(col is None or str(col).strip()=="" for col in raw_df.columns):
        st.error("æœ‰æ¬„ä½åç¨±æ˜¯ç©ºç™½ï¼Œè«‹è£œé½Šå¾Œå†ä¸Šå‚³ã€‚")
        st.stop()

    st.success(f"âœ… æˆåŠŸè®€å–å·¥ä½œè¡¨ï¼š{chosen_sheet}ï¼Œå…± {raw_df.shape[0]} åˆ— Ã— {raw_df.shape[1]} æ¬„")

    df_clean = clean_dataframe(raw_df)

    numeric_cols = get_pure_numeric_cols(df_clean)
    if not numeric_cols:
        st.error("æœªåµæ¸¬åˆ°å¯å®Œå…¨è½‰æˆæ•¸å­—çš„æ¬„ä½ï¼Œè«‹ç¢ºèªè¡¨æ ¼ä¸­æœ‰é‡‘é¡/æ•¸é‡æ¬„ä½ã€‚")
        st.stop()

    # Step2 ç›®æ¨™æ¬„ä½
    step_header_small("Step 2. é¸æ“‡åˆ†æç›®æ¨™æ¬„ä½ (ç´”æ•¸å­—æ¬„)")
    big_bold_label("è«‹é¸æ“‡æ¬²åˆ†æä¹‹ç›®æ¨™æ¬„ä½ï¼ˆä¾‹å¦‚ï¼šæç›Šã€é‡‘é¡ã€å ±å»¢æ•¸é‡...)")

    st.session_state.setdefault("target_col", None)
    st.session_state["target_col"] = pick_one_from_grid_scrollable(
        options=numeric_cols,
        current_value=st.session_state["target_col"],
        key_prefix="targetcol_page1"
    )
    target_col = st.session_state["target_col"]

    if target_col is None:
        st.warning("è«‹é¸ä¸€å€‹åˆ†ææŒ‡æ¨™æ¬„ä½ã€‚")
        st.stop()

    col_sum = pd.to_numeric(df_clean[target_col], errors="coerce").fillna(0).sum()
    st.info(f"ğŸ“Š `{target_col}` æ¬„ä½ç¸½åˆï¼š{col_sum:,.2f}")

    # Step3 æ¨¡å¼
    step_header_small("Step 3. é¸åˆ†ææ¨¡å¼")
    big_bold_label("ä½ æƒ³è¦çœ‹å“ªä¸€é¡ä¸»å› ï¼Ÿ")

    mode_label = st.radio(
        "",
        ["æœ€é«˜è²¢ç» (èª°ä½”æœ€å¤š-contribution)", "æœ€å¤§è™§æ (èª°æœ€è³ éŒ¢-loss)"],
        horizontal=True,
        key="page1_mode"
    )
    internal_mode = "contribution" if "è²¢ç»" in mode_label else "loss"

    # Step4 åˆ†ç¾¤æ¬„ä½
    step_header_small("Step 4. é¸åˆ†ç¾¤æ¬„ä½ (å¦‚ï¼šå®¢æˆ¶ã€åœ°å€ã€æ¥­å‹™å“¡...)")
    big_bold_label("è«‹é¸æ“‡è¦åˆ†ç¾¤çš„æ¬„ä½")

    all_possible_dims = [c for c in df_clean.columns if c != target_col]
    if not all_possible_dims:
        st.error("ç„¡å¯ç”¨åˆ†ç¾¤æ¬„ä½ã€‚")
        st.stop()

    st.session_state.setdefault("dim_col", None)
    st.session_state["dim_col"] = pick_one_from_grid_scrollable(
        options=all_possible_dims,
        current_value=st.session_state["dim_col"],
        key_prefix="dimcol_page1"
    )
    dim_col = st.session_state["dim_col"]

    if dim_col is None:
        st.warning("è«‹å…ˆé¸æ“‡åˆ†ç¾¤æ¬„ä½ã€‚")
        st.stop()

    # Step5 å±•é–‹æ˜ç´°
    summary_df, total_value = summarize_by_dimension(
        df_clean,
        target_col,
        dim_col,
        internal_mode
    )
    if summary_df.empty:
        st.warning("æ²’æœ‰è³‡æ–™å¯ç”¨ä¾†è¨ˆç®—(ä¾‹å¦‚æ²’æœ‰è² æ•¸)ã€‚")
        st.stop()

    if internal_mode == "contribution":
        st.write(f"ä¾ã€Œ{dim_col}ã€åˆ†çµ„å¾Œï¼Œ`{target_col}` æœ€å¤§çš„ Top 5ï¼š")
    else:
        st.write(f"ä¾ã€Œ{dim_col}ã€åˆ†çµ„å¾Œï¼Œæœ€è³ éŒ¢çš„ Top 5ï¼š")

    st.dataframe(summary_df)

    step_header_small("Step 5. å±•é–‹æ˜ç´°")
    big_bold_label(f"è«‹é¸ä¸€å€‹ã€{dim_col}ã€çš„å€¼æª¢è¦–æ˜ç´°")

    candidate_values = summary_df[dim_col].astype(str).tolist()

    st.session_state.setdefault("selected_val", None)
    st.session_state["selected_val"] = pick_one_from_grid_scrollable(
        options=candidate_values,
        current_value=st.session_state["selected_val"],
        key_prefix="valsel_page1",
        box_height_px=200
    )
    selected_val = st.session_state["selected_val"]

    if selected_val is None:
        st.warning("è«‹å…ˆé¸ä¸€å€‹ç¾¤çµ„å€¼ã€‚")
        st.stop()

    detail_df = filter_df_by_dim_value(df_clean, dim_col, selected_val)

    group_sum = pd.to_numeric(detail_df[target_col], errors="coerce").fillna(0).sum()
    pct = (group_sum / total_value * 100) if total_value != 0 else 0

    st.markdown(f"**ç›®å‰æª¢è¦–ï¼š** {dim_col} = {selected_val}")
    st.markdown(f"**{target_col} åˆè¨ˆï¼š** {group_sum:.2f}ï¼ˆå æ¯” {pct:.2f}%ï¼‰")

    st.dataframe(detail_df)

    # Step6 åŒ¯å‡º
    step_header_small("Step 6. ä¸‹è¼‰æ˜ç´°")
    big_bold_label("åŒ¯å‡ºé€™æ¬¡åˆ†æçµæœï¼ˆExcelï¼‰")

    metadata = pd.DataFrame([{
        "timestamp_utc": datetime.utcnow().isoformat(),
        "source_file": uploaded_file.name,
        "sheet": chosen_sheet,
        "target_col": target_col,
        "mode": internal_mode,
        "dim_col": dim_col,
        "selected_val": selected_val,
        "group_sum": group_sum,
        "pct_of_total(%)": pct,
    }])

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        sheet_name = "åˆ†æçµæœ"
        metadata.to_excel(
            writer,
            sheet_name=sheet_name,
            startrow=0,
            index=False
        )

        start_row = len(metadata) + 2
        detail_df.to_excel(
            writer,
            sheet_name=sheet_name,
            startrow=start_row,
            index=False
        )

    st.download_button(
        label="â¬‡ ä¸‹è¼‰ Excel æ˜ç´°",
        data=output.getvalue(),
        file_name=f"åˆ†æçµæœ_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )


########################################################
# 5. ç¬¬äºŒé ï¼šSmartArté¢¨æ ¼ æ ¹å› åˆ†ææ¨¹ (HTML/CSS)
########################################################

def page_root_cause_tree():
    st.markdown("#### ğŸŒ³ æ ¹å› åˆ†ææ¨¹ (SmartArtéšå±¤é¢¨æ ¼)")

    st.markdown(
        "<div style='font-size:0.8rem;color:#444;margin-bottom:0.5rem;'>"
        "ä¸Šå‚³æª”æ¡ˆ â†’ é¸ KPI â†’ å¾ã€ç›®å‰æœ€å¾Œä¸€å±¤ã€æŒ‡å®šæŸå€‹ç¯€é»å¾€ä¸‹æ‹† â†’ é¸æ¬„ä½ã€‚<br>"
        "ç³»çµ±åªå…è¨±ä¸€æ¢è·¯å¾‘å¾€ä¸‹é‘½ï¼Œé¿å…åŒæ™‚å¾å¤šå€‹ç¯€é»åˆ†æ”¯ï¼Œä¿æŒåƒ Power BI Decomposition Treeã€‚<br>"
        "åˆªé™¤ä¸­é–“å±¤å¾Œï¼Œä¸‹é¢çš„å±¤å°±è‡ªå‹•è®Šæˆæ–°çš„æœ€å¾Œä¸€å±¤ï¼Œç¹¼çºŒå¾€ä¸‹æ‹†ã€‚"
        "</div>",
        unsafe_allow_html=True
    )

    init_rca_layers()

    # ä¸Šå‚³æª”æ¡ˆ
    uploaded_file = st.file_uploader(
        "ä¸Šå‚³ Excel (.xls / .xlsx / .xlsm) (æ­¤é åªè®€ç¬¬ä¸€å€‹å·¥ä½œè¡¨)",
        type=["xls","xlsx","xlsm"],
        key="page2_uploader"
    )
    if uploaded_file is None:
        st.stop()

    try:
        xls = pd.ExcelFile(uploaded_file)
        first_sheet = xls.sheet_names[0]
        df_raw = pd.read_excel(uploaded_file, sheet_name=first_sheet, header=0)
    except Exception as e:
        st.error(f"è®€æª”å¤±æ•—ï¼š{e}")
        st.stop()

    # è¡¨é ­æª¢æŸ¥
    if df_raw.columns.duplicated().any():
        st.error("è¡¨é ­æœ‰é‡è¤‡æ¬„ä½åç¨±ï¼Œè«‹ä¿®æ­£å¾Œå†ä¸Šå‚³ã€‚")
        st.stop()
    if any(col is None or str(col).strip()=="" for col in df_raw.columns):
        st.error("æœ‰æ¬„ä½åç¨±æ˜¯ç©ºç™½ï¼Œè«‹è£œé½Šå¾Œå†ä¸Šå‚³ã€‚")
        st.stop()

    df_clean = clean_dataframe(df_raw)

    # KPI æ¬„
    all_numeric_cols = get_pure_numeric_cols(df_clean)
    if not all_numeric_cols:
        st.error("æœªåµæ¸¬åˆ°å¯å®Œå…¨è½‰æˆæ•¸å­—çš„æ¬„ä½(ä¾‹å¦‚é‡‘é¡/æ·¨åˆ©/æ•¸é‡)ã€‚")
        st.stop()

    # MODIFICATION 3: å¾æ•¸å€¼æ¬„ä½ä¸­ï¼Œå‰”é™¤å·²ç¶“è¢«ç”¨åœ¨æ¨¹ä¸­çš„ç¶­åº¦
    used_dims_in_tree = set()
    if "rca_layers" in st.session_state:
        for layer in st.session_state["rca_layers"]:
            used_dims_in_tree.add(layer["split_dim"])
            for dim_key in layer["parent_filters"].keys():
                used_dims_in_tree.add(dim_key)

    available_kpis = [col for col in all_numeric_cols if col not in used_dims_in_tree]

    if not available_kpis:
        st.error("æ‰€æœ‰æ•¸å€¼æ¬„ä½éƒ½å·²è¢«ç”¨æ–¼ç¶­åº¦æ‹†è§£ï¼Œç„¡æ³•é¸æ“‡KPIã€‚è«‹å…ˆæ¸…ç©ºæˆ–åˆªé™¤éƒ¨åˆ†æ¨¹çš„å±¤ç´šã€‚")
        st.stop()

    target_col = st.selectbox(
        "è«‹é¸æ“‡è¦åˆ†æçš„ KPI (æ•¸å€¼æ¬„ä½)",
        available_kpis,
        key="page2_target_col"
    )

    # MODIFICATION 2: å¦‚æœKPIè®Šäº†ï¼Œç”¨ç¾æœ‰çµæ§‹é‡ç®—æ•´æ£µæ¨¹
    st.session_state.setdefault("page2_last_target_col", None)
    if target_col != st.session_state.get("page2_last_target_col") and st.session_state.get("page2_last_target_col") is not None:
        with st.spinner(f"åµæ¸¬åˆ°KPIè®Šæ›´ç‚º {target_col}ï¼Œæ­£åœ¨é‡ç®—æ•´æ£µæ¨¹..."):
            recalculated_layers = []
            for layer in st.session_state.get("rca_layers", []):
                df_sub = apply_filters_to_df(df_clean, layer["parent_filters"])
                new_groups = compute_top_groups_with_other(df_sub, target_col, layer["split_dim"], top_n=5)
                
                if new_groups:
                    recalculated_layers.append({
                        "parent_filters": layer["parent_filters"],
                        "split_dim": layer["split_dim"],
                        "groups": new_groups,
                    })
            st.session_state["rca_layers"] = recalculated_layers
        st.toast(f"å·²ä½¿ç”¨æ–°çš„KPI '{target_col}' é‡ç®—æ ¹å› æ¨¹ï¼")
    
    st.session_state["page2_last_target_col"] = target_col
    

    # å¯æ‹†åˆ†çš„ç¶­åº¦æ¬„ä½
    all_dims = [c for c in df_clean.columns if c != target_col]

    # ç‰ˆé¢ï¼šå·¦=æ¨¹ï¼›å³=æ§åˆ¶é¢æ¿
    main_col, side_col = st.columns([4, 1.6], gap="large")

    # ========== å³å´ï¼šäº’å‹•æ§åˆ¶ ==========
    with side_col:
        st.markdown(
            "<div style='font-size:0.9rem;font-weight:600;color:#000;"
            "margin-bottom:0.5rem;border-bottom:1px solid #ccc;'>å±•é–‹ / ç¶­è­·æ¨¹</div>",
            unsafe_allow_html=True
        )

        # åªå…è¨±å¾ã€Œæœ€å¾Œä¸€å±¤ã€å¾€ä¸‹é‘½
        parent_choices = build_parent_candidates_from_tail()
        parent_labels = [lab for (lab, _) in parent_choices]
        sel_parent_label = st.selectbox(
            "æˆ‘è¦åœ¨å“ªå€‹ç¯€é»ä¸‹é¢æ–°å¢ä¸‹ä¸€å±¤ï¼Ÿ(åªèƒ½é¸ç›®å‰æœ€å¾Œä¸€å±¤)",
            options=parent_labels,
            key="rca_parent_select"
        )

        parent_filters = {}
        for (lab, fdict) in parent_choices:
            if lab == sel_parent_label:
                parent_filters = fdict.copy()
                break

        # é‡å°é€™å€‹çˆ¶ç¯€é»ï¼Œè¨ˆç®—å¯ç”¨ä¾†æ‹†åˆ†çš„æ¬„ä½ï¼ˆä¾å½±éŸ¿åŠ›æ’åºï¼‰
        df_parent_sub = apply_filters_to_df(df_clean, parent_filters)

        # é€™å€‹çˆ¶ç¯€é»æœ¬èº«ä»¥å‰ç”¨éå“ªäº› split_dimï¼Ÿ
        used_dims_here = []
        for lyr in st.session_state["rca_layers"]:
            if lyr["parent_filters"] == parent_filters:
                used_dims_here.append(lyr["split_dim"])

        ranked_dims = rank_candidate_dims(
            df_parent_sub, target_col, all_dims, used_dims_here
        )

        if len(ranked_dims)==0:
            st.info("åœ¨é€™å€‹ç¯€é»ä¸‹ï¼Œæ²’æœ‰æ›´å¤šå¯æ‹†çš„æ¬„ä½ (æˆ–éƒ½æ‹†éäº†)")
        else:
            sel_split_dim = st.selectbox(
                "ä¸‹ä¸€å±¤è¦ç”¨å“ªå€‹æ¬„ä½åˆ†è§£ï¼Ÿ(ä¾å½±éŸ¿åŠ›æ’åº)",
                options=ranked_dims,
                key="rca_split_dim_select"
            )

            if st.button("â• åŠ åˆ°æ¨¹è£¡ (å±•é–‹ä¸‹ä¸€å±¤)"):
                add_new_layer(
                    df_clean=df_clean,
                    target_col=target_col,
                    parent_filters=parent_filters,
                    split_dim=sel_split_dim,
                    top_n=5
                )
                st.rerun()

        # ===== åˆªé™¤å±¤ =====
        st.markdown(
            "<div style='font-size:0.9rem;font-weight:600;color:#000;"
            "margin:1rem 0 0.5rem;border-bottom:1px solid #ccc;'>åˆªé™¤æŸå±¤æ‹†è§£</div>",
            unsafe_allow_html=True
        )

        if len(st.session_state["rca_layers"])==0:
            st.write("ç›®å‰æ²’æœ‰ä»»ä½•å±•é–‹çš„å±¤")
        else:
            layer_labels = []
            for i,lyr in enumerate(st.session_state["rca_layers"]):
                pf = lyr["parent_filters"]
                pf_txt = "å…¨é«”" if len(pf)==0 else ", ".join([f"{k}={v}" for k,v in pf.items()])
                layer_labels.append(f"{i}. çˆ¶æ¢ä»¶[{pf_txt}] â†’ æ‹†åˆ†æ¬„ä½:{lyr['split_dim']}")

            # MODIFICATION 1: é è¨­ç‚ºæœ€å¾Œä¸€å€‹é¸é …
            sel_layer_to_remove = st.selectbox(
                "é¸æ“‡è¦åˆªé™¤çš„å±¤ï¼š",
                options=layer_labels,
                key="rca_remove_layer_select",
                index=len(layer_labels) - 1
            )

            if st.button("ğŸ—‘ åˆªé™¤æ­¤å±¤"):
                idx_to_remove = layer_labels.index(sel_layer_to_remove)
                remove_layer_by_index(idx_to_remove)
                st.rerun()

        # ===== å…¨éƒ¨æ¸…é™¤ =====
        st.markdown(
            "<div style='font-size:0.9rem;font-weight:600;color:#000;"
            "margin:1rem 0 0.5rem;border-bottom:1px solid #ccc;'>å…¨éƒ¨æ¸…é™¤</div>",
            unsafe_allow_html=True
        )

        if st.button("ğŸ’£ æ¸…ç©ºæ•´æ£µæ¨¹ (å›åˆ°åªæœ‰KPI)"):
            st.session_state["rca_layers"] = []
            st.rerun()

    # ========== å·¦å´ï¼šæ¨¹å½¢ SmartArt è¦–è¦º ==========
    with main_col:
        st.markdown(
            "<div style='font-size:0.9rem;font-weight:600;color:#000;"
            "margin-bottom:0.5rem;'>ç›®å‰çš„æ ¹å› æ¨¹ (SmartArté¢¨æ ¼)</div>",
            unsafe_allow_html=True
        )

        levels = build_tree_path(df_clean, target_col)
        html_tree = render_tree_html(levels)

        st.markdown(html_tree, unsafe_allow_html=True)

        st.caption(
            "èªªæ˜ï¼šå¡ç‰‡é¡¯ç¤ºç¾¤çµ„åç¨±ã€è©²ç¾¤çµ„çš„ KPI åˆè¨ˆã€"
            "ä»¥åŠè©²ç¾¤çµ„å°ä¸Šå±¤(çˆ¶ç¯€é»)çš„å æ¯”ã€‚ç´…è‰²=è™§æè¼ƒå¤§ï¼Œç¶ è‰²=ç²åˆ©ã€‚"
        )


########################################################
# 6. é ‚éƒ¨è¶…æ‰å°è¦½åˆ—
########################################################

def render_top_nav():
    st.markdown(
        """
        <style>
        div[data-baseweb="radio"] > div { margin-bottom: 0.2rem; }
        </style>
        """,
        unsafe_allow_html=True
    )

    nav_col = st.container()
    with nav_col:
        c1, c2 = st.columns([0.12, 0.88])
        with c1:
            st.markdown(
                "<div style='font-size:0.7rem; color:#666; line-height:1; padding-top:2px;'>åŠŸèƒ½é¸å–®</div>",
                unsafe_allow_html=True
            )
        with c2:
            st.radio(
                label="åŠŸèƒ½é¸å–®",
                options=["ğŸ“Š Excelè¡¨æ ¼åˆ†æ", "ğŸŒ³ æ ¹å› åˆ†ææ¨¹"],
                horizontal=True,
                key="main_page_selector",
                label_visibility="collapsed",
            )
    st.markdown(
        """
        <div style="
            border-top:1px solid #CCC;
            margin-top:4px;
            margin-bottom:8px;
        "></div>
        """,
        unsafe_allow_html=True
    )

    return st.session_state["main_page_selector"]


########################################################
# 7. ä¸»æµç¨‹
########################################################

if "main_page_selector" not in st.session_state:
    st.session_state["main_page_selector"] = "ğŸ“Š Excelè¡¨æ ¼åˆ†æ"

current_page = render_top_nav()

if current_page == "ğŸ“Š Excelè¡¨æ ¼åˆ†æ":
    page_table_analysis()
else:
    page_root_cause_tree()
